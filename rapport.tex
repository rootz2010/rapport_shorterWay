\documentclass[a4paper,12pt,final] {article}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[frenchb]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[autolanguage]{numprint}
\usepackage{eurosym}
\usepackage{makeidx}
\usepackage[pdftex]{hyperref}
\makeindex
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{shapes}
\usepackage{color}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{geometry}
\usepackage{url}
\usepackage{pst-node, pstricks}

% for the pictures
\graphicspath{{./include/}} % déclaration du dossier d'enregistrement des photos
\DeclareGraphicsExtensions{.png,.eps,.jpg} % png, jpg etc. ne compile pas en DVI ... préférer l'eps
% enlever les extensions aux photos ?

% for the code
\usepackage{listings}
\definecolor{vert}{rgb}{0.2,0.6,0.4} 
\definecolor{grey}{rgb}{0.95,0.95,0.95}
\lstset{language=c,frame=single, breaklines=true, basicstyle=\ttfamily,backgroundcolor=\color{grey},basicstyle=\scriptsize, keywordstyle=\color{blue}, commentstyle=\color{vert}, stringstyle=\color{red}, identifierstyle=\ttfamily,showstringspaces=false, extendedchars=true}

\def\subsubsubsection{\paragraph}
\def\subsubsubsubsection{\subparagraph}

\hypersetup{pdfpagemode=none,
pdfstartview=FitH,
pdfkeywords={LaTeX: document typesetting system},
breaklinks=true,
colorlinks=true,
linkcolor=black,
citecolor=black,
filecolor=black,
urlcolor=blue
}


\author{Ludovic Delaveau, Benjamin Loulier}
\title{Plus court chemin dans un graphe}

\lfoot{École Nationale Supérieure des Mines de Saint-Étienne}
\cfoot{}
\rfoot{\thepage/\pageref{LastPage}}
\lhead{Plus court chemin dans un graphe}
\chead{}
\rhead{Loulier - Delaveau}

\pagestyle{fancy}


\geometry{top=2cm}	
\geometry{bottom=3cm} % bottom margin

\begin{document}

% page de garde
\begin{titlepage}

\vspace*{\fill} % pour remplir le haut de la page
    \hspace*{\fill}

\begin{center}

\centering
\includegraphics[scale=0.3]{icone}\\[2cm] % bison fûté

% Title
\rule{15cm}{0.2mm} \\[0.4cm]
{ \huge \bfseries Plus court chemin dans un graphe}\\[0.4cm]
 \rule{15cm}{0.2mm} \\[0.4cm]

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Auteurs :}\\
Benjamin \textsc{Loulier}\\
Ludovic \textsc{Delaveau}\\
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Tuteurs :} \\
Roland \textsc{Jegou}\\
Michel \textsc{Beigbeder}\\
\end{flushright}
\end{minipage}
 
\vfill
Projet d'Axe informatique 2009-2010
\end{center}

\end{titlepage}

\newpage

\setcounter{page}{2} 
\tableofcontents

\newpage

\section{Introduction}

Le fait de trouver le plus court chemin dans un graphe (pathfinding en anglais) trouve énormément d'applications dans l'industrie. Un premier exemple d'application qui nous vient à l'esprit est évidemment les utilisations faites dans les GPS pour le calcul d'itinéraires, avec une valuation donnée en fonction de la distance d'un axe, mais également en fonction de l'importance de l'axe, voire même en fonction du trafic et de l'encombrement. D'autres utilisations moins connues sont par exemple les algorithmes associés au routage des données dans un réseau (application très sensible et nécessitant des algorithmes les plus performants possible, afin d'optimiser les temps de réponse entre les routeurs) ou à de l'optimisation de process.\\

Le travail fait ici s'appuie sur les graphes orientés valués, qui sont une forme de graphe la plus générique, et les algorithmes implémentés peuvent très facilement s'adaptés à des graphes non-orientés.\\

Nous avons pris le parti dans ce projet de ne traiter que des algorithmes trouvant exactement le chemin le plus court et pas un chemin optimisé. Nous avons décidé de ne pas utiliser des algorithmes approchés tels que A* car nous les avons déjà traité en première année dans le cadre du cours de java. Nous avons donc étudié trois algorithmes : L'algorithme de Bellman-Ford, l'algorithme de Dijkstra et l'algorithme de Dantzig.\\

Ce rapport se divise en trois parties principales, présentant d'abord les graphes ainsi que les structures de données que nous avons utilisées, puis les algorithmes que nous avons implémentés. Enfin l'application que nous avons réalisée sera présentée.

\newpage
\section{Définitions et structures de données}
\subsection{Graphe}

Un graphe simple est un couple formé de deux ensembles: \\
$$G=(X,A)$$ avec X l'ensemble des sommets, et A l'ensemble des arêtes.\\
$$G=(X,A,v)$$ si on ajoute la possibilité de donner une valeur différentes aux arêtes, nous avons dans ce cas un graphe valué et v est l'ensemble des valuations.\\
Un graphe peut être non orienté, auquel cas une arête entre un sommet A et B permet aussi bien de se rendre de A en B et de en A. Il peut être aussi orienté, dans ce cas une arête ne peut être parcourue que dans un sens.

\begin{figure}[htdp]
\begin{psmatrix}[mnode=circle]
         &   &   & C & E            \\
$\alpha$ & A & B & D &   & $\omega$ \\
         &   &   & F
\end{psmatrix}

\psset{arrows=->,
       labelsep=1mm,
       shortput=nab}

\ncline{2,1}{2,2}^{0} 
\ncline{2,2}{2,3}^{2} 
\ncline{2,3}{1,4}^{4} 
\ncline{2,3}{2,4}^{4} 
\ncline{2,3}{3,4}^{4}
\ncline{1,4}{1,5}^{3}
\ncarc[arcangle=10]{2,4}{1,5}^{2}
\ncarc[arcangle=10]{1,5}{2,4}^{2}
\ncline{3,4}{2,6}^{4}
\ncline{1,5}{2,6}^{10}

\caption{Exemple de graphe valué orienté}
\end{figure}
\subsection{Matrice d'adjacence}

plop
\begin{figure}[htdp]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
0 & 4 & $\infty$\\
\hline
8 & 0 & 3 \\
\hline
42 & $\infty$ & 0 \\
\hline
\end{tabular}
\end{center}
\caption{matrice d'adjacence}
\end{figure}

Dans notre programme nous avons utilisé un tableau d'entiers, qui sont alloués dynamiquement puisque la taille du graphe est déterminée pendant l'exécution par l'utilisateur :
\begin{lstlisting}
int ** matrix;
\end{lstlisting}

\subsection{Tableau de liste chaînées}

Voilà la définition utilisée dans notre programme de la structure de données de liste chaînées :
\begin{lstlisting}
struct chained_list {
	int number;
	int value;
	struct chained_list * next;
};
\end{lstlisting}

Nous utilisons un tableau de liste chaînées, dont la déclaration est :
\begin{lstlisting}
struct chained_list ** list;
\end{lstlisting}
Il s'agit d'un double pointeur, puisqu'il est alloué également dynamiquement, pour les mêmes raisons que la matrice d'adjacence.

\subsection{Matrice de prédécesseur}

La matrice de prédécesseurs est l'une des deux structures de données utilisées en tant que structure de données de sortie. Elle est utilisée dans les algorithmes de Bellman-Ford et de Dijkstra, ainsi que dans une certaine mesure dans celui de Dantzig, comme nous le verrons par la suite.\\

Une matrice de prédécesseur est définie pour un noeud de départ donné. Cette matrice, telle que nous l'avons implémentée dans notre programme est de dimension ``nombre de noeuds" * 2, et stocke pour un noeud de départ donné ses prédécesseurs et les distances associées. La première colonne contient les poids des arcs qui relient le noeud de départ à la deuxième colonne, qui contient les prédécesseurs. On donne un poids nul à l'arc reliant le noeud de départ  à lui-même, et on indique $\infty$ comme prédecesseur.\\

La figure 3 donne la matrice de prédécesseur du noeud 0 du graphe décrit par la matrice d'adjacence donnée en exemple à la figure 2.\\ % attention au numéro !

\begin{figure}[htdp]
\begin{center}
\begin{tabular}{|c|c|}
\hline
0 &$\infty$\\
\hline
4 & 1 \\
\hline
$\infty$ & $\infty$ \\
\hline
\end{tabular}
\end{center}
\caption{Matrice de prédécesseur pour le noeud 0 de la figure 2}
\end{figure}%

Le code utilisé pour définir la matrice n'est pas différent de celui de la matrice d'adjacence. La taille est toujours donnée dynamiquement, avec la différence cette fois que la matrice n'a que deux colonnes.
\begin{lstlisting}
int ** predecessor_matrix;
\end{lstlisting}

\subsection{``Matrice de Dantzig"}

Cette matrice, qui est comme son nom l'indique utilisée dans l'algorithme de Dantzig pour collecter les résultats, est une matrice ``nombre de noeuds" * ``nombre de noeuds" * 2. Dantzig, comme nous le verrons par la suite travaille sur le graphe entier, faisant  le calcul sur tous les sommets.\\

Dès lors, tel que nous avons implémenté la matrice, il s'agit simplement d'un tableau de n matrices de prédécesseurs, où n est le nombre de noeuds dans le graphe.\\

La figure 4 présente un exemple de cette matrice pour la matrice d'adjacence donnée à la figure 2. La matrice n'est ici pas le résultat d'un calcul de l'algorithme, et des chemins possibles n'y figurent pas, tandis que des chemins plus courts ne sont pas notés.\\ % attention au numéro !

\begin{figure}[htdp]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
(0, $\infty$) & (4, 1) & ($\infty$, $\infty$) \\
\hline
(8, 0) & (0, $\infty$) & (3, 2)\\
\hline
(42, 0) & ($\infty$, $\infty$) & (0, $\infty$)\\ 
\hline
\end{tabular}
\end{center}
\caption{Matrice utilisée dans l'algorithme de Dantzig}
\end{figure}

L'implémentation d'une telle matrice est faite également très simplement, suivant ce qui est fait pour la matrice de prédécesseur. On a ici une matrice à trois dimensions, et donc un triple pointeur sur un entier :
\begin{lstlisting}
int *** matrix;
\end{lstlisting}

\subsection{choix des types de données}

Nous avons choisi d'utiliser des entiers pour représenter à la fois les noeuds et aussi leur valeur. Il nous a en effet semblé suffisant de se limiter à INT\_MAX en terme de nombre de noeuds. Cela représente tout de même \nombre{2147483647} noeuds, et une plage de valuation suffisante. La machine sera tout de façon d'abord limitée en terme d'espace mémoire pour les représenter.\\

Dans l'implémentation des algorithmes nous avons surtout utilisé des matrices, par la rapidité de temps d'accès qu'elles permettent, et aussi par la simplicité de l'implémentation qu'elles permettent. Gérer une liste sans index est en effet plus compliqué, avec des algorithmes qui utilisent en permanence des valeurs stockées précédemment. Nous le verrons par la suite, mais tous les algorithmes se servent des valeurs déjà calculées, ou remplacent celles déjà stockées.\\

\newpage
\section{Présentation des trois algorithmes}

Nous avons donc implémenté les trois algorithmes principaux de recherche de chemins, qui sont ceux de Bellman-Ford, de Dijkstra et de Dantzig. Chacun a ses propres particularités, en particulier en terme de champ d'application.\\

Dans la suite de cette partie, nous allons étudier les différents algorithmes sur un même exemple, dont la matrice d'adjacence et la représentation sont données aux figures 5 et 6.\\ % attention au numéro !

\begin{figure}[htpd]
 \centering
 \begin{psmatrix}[mnode=circle]
	    & 2\\
	 1 &    & 4\\
	    & 3\\
\end{psmatrix}
	
\psset{arrows=->, labelsep=1mm, shortput=nab}
	\ncline{2,1}{1,2}^{6}
	\ncline{2,1}{3,2}^{1}
	\ncline{1,2}{2,3}^{1}
	\ncline{3,2}{1,2}^{1}
	\ncline{3,2}{2,3}^{1}

  \caption{Le graphe qui est utilisé dans les sections suivantes}
\end{figure}

\begin{figure}[htpd]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
0 & 6 & 1 & $\infty$\\
\hline
$\infty$ & 0 & $\infty$ & 1\\
\hline
$\infty$ & 1 & 0 & 1\\
\hline
$\infty$ & $\infty$ & $\infty$ & 0\\
\hline
\end{tabular}
\end{center}
\caption{La matrice d'adjacence associée au graphe de la figure précédente}
\end{figure}

%%%%%%%%%%%%Fin de l'intro de la partie 3%%%%%%%%%%%
\subsection{Bellman-Ford}
Bellman-Ford permet de trouver la matrice de prédécesseur pour un point de départ donné.\\
Bellman Ford fonctionne en regardant pour chaque sommet du graphe les prédécesseurs et en comparant les poids affectés à chaque sommet. Voici le pseudo code de l'algorithme de Bellman-Ford.
\begin{lstlisting}
 bool Bellman_Ford( G, s) 
 
   initialisation ( G, s)  // les poids de tous les sommets sont mis a +infini 
                           // le poids du sommet initial a 0
   pour i=1 a Nombre de sommets -1 faire
        pour chaque arc (u, v) du graphe faire
           paux := poids(u) + poids(arc(u, v)); 
           si paux < poids(v) alors
               pred(v) := u; 
               poids(v) := paux; 
   pour chaque arc (u, v) du graphe faire
       si poids(u) + poids(arc(u, v)) <poids(v) alors
         retourner faux 
   retourner vrai
\end{lstlisting}
%%%%%%%%%%%%%Fin de bellman%%%%%%%%%%%%%%%
\subsection{Dijkstra}
%%%%%%%%%%%%%%Fin de dijkstra%%%%%%%%%%%%%%%
\subsection{Dantzig}

Dantzig est un algorithme qui étudie tout le graphe, contrairement aux deux algorithmes précédents, et peut travailler comme Bellman-Ford sur des graphes à valuation négative. Il permet également de détecter les circuits.\\

Le principe général de l'algorithme est de travailler sur des sous-graphes jusqu'à parvenir au graphe principal. L'algorithme peut se diviser en trois parties, comme le montre le pseudo-code ci-dessous :
\begin{lstlisting}
initialisation(); /* construction de la matrice de sortie */

degre_graphe = 0; /* le niveau du graphe par rapport au graphe total */
circuit  = faux;

tant que degre_graphe <= taille_graphe - 1 et non circuit faire
|  i = 1;
|  tant que i <= degre_graphe et non circuit faire
|    |  pour j = 1 a k faire
|    |    longueur  = d(i,j) + v(j, k + 1); /* d est la distance deja calculee, v la valuation */
|    |      si longueur < d(i, k+1) alors
|    |        d(i, k+1) = longueur;
|    |         p(i, k+1) = j; /* p est le predecesseur de k+1 en partant de i */
|    |    longueur  = d(i,j) + v(j, k + 1)
|    |    si longueur < d(k+1, i) alors
|    |      d(k+1, i) = longueur;
|    |    si i = j alors
|    |      p(k+1, i) = k + 1;
|    |    sinon
|    |      p(k+1, j) = p(j,i);
|    |  si d(k+1, i) + d(i, k+1) < 0 alors
|    |    circuit = vrai;
|    |  i = i + 1;
|  si non circuit alors
|   |  pour i = 1 a k faire
|   |    pour j = 1 a k faire
|   |      longueur = d(i, k+1) + d(k+1, j);
|   |      si longueur < d(i,j) alors
|   |        d(i, j) = longueur;
|   |        p(i, j) = p(k+1, j);
\end{lstlisting}

La première partie est une initialisation de la matrice de sortie, comme montré à la figure 7. Il s'agit de donner un coup infini avec aucun prédécesseur à tous les noeuds, sauf la diagonale, où on met un coup nul avec comme prédécesseur le même noeud.\\% attention au numéro !

% k = 0
\begin{figure}[htpd]
\begin{center}
\begin{psmatrix}[mnode=circle]
{\color{red} \bf 1}\\
\end{psmatrix}
\end{center}
\caption{initialisation}
\end{figure}

\begin{figure}[htpd]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
(0, 1) & ($\infty$, $\infty$) & ($\infty$, $\infty$) & ($\infty$, $\infty$) \\
\hline
($\infty$, $\infty$) & (0, 2) & ($\infty$, $\infty$) & ($\infty$, $\infty$) \\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 3) & ($\infty$, $\infty$)\\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 4) \\
\hline
\end{tabular}
\end{center}
\caption{initialisation}
\end{figure}

% k = 1
\begin{figure}[h!]
\begin{center}
\begin{psmatrix}[mnode=circle]
 & {\color{red} \bf 2}\\
 1\\
 & {\color{red} \bf 3}\\
\end{psmatrix}

\psset{arrows=->, labelsep=1mm, shortput=nab}
	\ncline{2,1}{1,2}^{6}
	\ncline{2,1}{3,2}^{1}

\end{center}
\caption{k = 1}
\end{figure}

\begin{figure}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
(0, 1) & {\color{red} \bf (6, 1)} & {\color{red} \bf (1, 1)} & ($\infty$, $\infty$) \\
\hline
($\infty$, $\infty$) & (0, 2) & ($\infty$, $\infty$) & ($\infty$, $\infty$) \\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 3) & ($\infty$, $\infty$)\\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 4) \\
\hline
\end{tabular}
\end{center}
\caption{Matrice pour k = 1}
\end{figure}

Une fois la matrice remplie avec les valeurs de départ, on incrémente la taille du graphe jusqu'à obtenir le graphe total. Le principe est de chercher un noeud appartenant au graphe déjà calculé, qui minimise la distance déjà obtenue entre le noeud de départ est le noeud que l'on veut ajouter au graphe. Il s'agit donc de trouver un noeud intermédiaire entre i (noeud de départ) et  k+1 (noeud d'arrivée) qui minimise la distance entre ces deux extrémités.\\

% k = 2
\begin{figure}[htpd]
 \centering
 \begin{psmatrix}[mnode=circle]
	    & {\color{red} \bf 2}\\
	 1 &    & {\color{red} \bf 4}\\
	    & 3\\
\end{psmatrix}
	
\psset{arrows=->, labelsep=1mm, shortput=nab}
	\ncline{2,1}{1,2}^{6}
	\ncline{2,1}{3,2}^{1}
	\ncline{1,2}{2,3}^{1}
	\ncline{3,2}{1,2}^{1}
	\ncline{3,2}{2,3}^{1}

  \caption{k = 2}
\end{figure}

Lorsque l'on trouve un tel noeud, on va modifier la matrice de sortie, en notant dans la première colonne de la matrice de prédécesseur la nouvelle distance, et dans la deuxième colonne le noeud par lequel il faut passer.\\

\begin{figure}[htpd]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
(0, 1) & (6, 1) & (1, 1) & ($\infty$, $\infty$) \\
\hline
($\infty$, $\infty$) & (0, 2) & ($\infty$, $\infty$) & {\color{red} \bf (1, 2)} \\
\hline
($\infty$, $\infty$) & {\color{red} \bf (1, 2)} & (0, 3) & {\color{red} \bf (1, 3)}\\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 4) \\
\hline
\end{tabular}
\end{center}
\caption{Matrice pour k = 2}
\end{figure}

À chaque fois que le graphe est agrandi, on va revérifier la matrice avec les nouveaux noeuds que l'on a rajouté, pour voir si un chemin plus court ne serait pas obtenu en passant par ces nouveaux noeuds pour atteindre des noeuds qui appartiennent au graphe de niveau inférieur.\\

% optimisation
\begin{figure}[h!]
 \centering
 \begin{psmatrix}[mnode=circle]
	    & {\color{red} \bf 2}\\
	 1 &    & {\color{red} \bf 4}\\
	    & 3\\
\end{psmatrix}
	
\psset{arrows=->, labelsep=1mm, shortput=nab}
	\ncline{2,1}{1,2}^{6}
	\ncline{2,1}{3,2}^{1}
	\ncline{1,2}{2,3}^{1}
	\ncline{3,2}{2,3}^{1}

  \caption{Phase d'optimisation}
\end{figure}

\begin{figure}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
(0, 1) & {\color{red} \bf (1, 4)} & (1, 3) & {\color{red} \bf (1, 3)} \\
\hline
($\infty$, $\infty$) & (0, 2) & ($\infty$, $\infty$) & (1, 2) \\
\hline
($\infty$, $\infty$) & (1, 2) & (0, 3) & (1, 3)\\
\hline
($\infty$, $\infty$) & ($\infty$, $\infty$) & ($\infty$, $\infty$) & (0, 4) \\
\hline
\end{tabular}
\end{center}
\caption{Matrice après optimisation}
\end{figure}

En terme de complexité en temps, on se retrouve avec cet algorithme en $o(n^{3})$. En effet on boucle n fois pour l'agrandissement du graphe, et à l'intérieur de cette boucle on se retrouve avec deux boucles imbriquées.\\

Pour la complexité en espace, on a une complexité en $o(n^{2})$, puisqu'on retourne une matrice à trois dimensions, dont deux dépendent de la taille du graphe.\\

Ces complexités sont à relativiser, dans la mesure où Dantzig travaille sur un graphe entier, alors que les deux algorithmes précédents travaillaient à partir d'un noeud de départ.\\

\subsection{Recherche du plus court chemin}

Les trois algorithmes précédents ne rendent pas directement le plus court chemin, mais les sommets le réalisant. Il y a donc un travail de reconstruction que nous avons fait à l'issue du calcul afin d'afficher le plus court chemin.\\

\begin{lstlisting}
struct chained_list* find_short(int** matrix, int departure, int arrival) {
	int node;
	struct chained_list * current;
	struct chained_list * former_current;
	
	/* one pointer on which we work, one pointer which is a backup of the previous current pointer :
	 * we build the chained_list like this : next <= (current->next) */
	
	node = arrival;
	
	do {
		current = (struct chained_list *) malloc(sizeof(struct chained_list));
		current -> number = node;
		current -> value = matrix[node][0];
		
		/* test to avoid trying to access to next which doesn't contain anything 
		 * during the first step. during this first step the tail must point to nothing*/
		if (node != arrival) {
			current -> next = former_current;
		}
		else {
			current -> next = NULL; /* nothing is also NULL :D */
		}
		node = matrix[node][1];
		//We end the loop sooner if there is no way to find a path
		if (node==INT_MAX) return NULL;
		former_current = current;
	} while (node != departure);
	
	return current;
}
\end{lstlisting}

Le principe de la fonction est de partir du noeud d'arrivée, et de remonter la matrice de prédécesseur jusqu'à arriver au noeud de départ. \\

La structure de donnée utilisée ici est la liste chaînée, qui convient particulièrement à la tâche dans la mesure où la structure est construite à l'envers du sens de lecture, sans connaître à l'avance la longueur nécessaire.\\

\newpage
\section{Application réalisée}
\subsection{Tests}
\subsection{Découpage du code}

Nous avons découpé notre code en trois grandes parties, dans des fichiers différents regroupant les catégories communes :

\begin{itemize}
\item{core} : en C, contenant le coeur de notre application
\item{io} : en C également, contenant les fonctions d'importation et d'exportation.
\item{contrôleur} : en Objective-C, qui permet d'interagir graphiquement avec le programme
\end{itemize}

Les fichiers d'en-tête ont bien évidemment été très utilisés, à la fois pour permettre cette compilation séparée, et pour définir les structures de données utilisées dans les fonctions.\\

\subsubsection{Fichier core.c}

Nous allons détailler un peu plus le fichier fondamental de notre application. Il contient tout d'abord des fonctions d'utilitaires pour l'application :
\begin{lstlisting}
/* Function to generate a random graph, this graph has a matrix form
 * if you want to have a chained list form use the convert_matrix function
 */
int ** random_graph(int nb_nodes, float completeness, float negative_probability);
/* function to convert a matrix into a chained list */
struct chained_list ** convert_matrix(int ** tab, int nb_nodes);
/*function to free a list*/
void free_list(struct chained_list * list);
/*function to free a table of chained list*/
void free_table_list(struct chained_list ** list, int nb_nodes);
/*function to free a 2 dimensions matrix*/
void free_2Dmatrix(int ** matrix, int row);
/* function to free a 3 dimensions matrix */
void free_3Dmatrix(int *** matrix, int row, int col);
\end{lstlisting}

La première fonction sert à générer des graphes aléatoires, qui vont servir à tester nos algorithmes. Les graphes sont générés par leur matrice d'adjacence. Un certain nombre de tirages est effectué dans la fonction, afin de respecter les différentes probabilités fixées en entrée, celles de remplissage de la matrice et celles de probabilité de présence de valuations négatives.\\

La fonction sert en effet à générer des graphes à valuation négative ou non, selon leur probabilité de présence. Les valuations sont comprises entre 0 et MAX\_LEN pour le cas des graphes à valuations positives, et entre - MAX\_LEN/2 + 1 et MAX\_LEN/2 pour les valuations négatives. L'intervalle est réduit pour des raisons de formatage de la sortie, qui est formatée pour des affichages de deux caractères.\\

\subsubsection{Fichier io.c}

Dans ce fichier sont contenues toutes les fonctions d'importation et d'exportation de graphes. Le format d'un fichier de stockage est le suivant :
\begin{lstlisting}
nb_nodes : nb
node node --
-- node  node
-- -- --
\end{lstlisting}

Les ``--" correspondent à l'absence d'arc entre les deux sommets.

\subsubsection{Le contrôleur}

Le contrôleur permet l'interaction de l'application avec l'utilisateur. À travers l'affichage l'utilisateur peut choisir la taille du graphe, ainsi que les différents paramètres associés au graphe. Il peut ensuite choisir les différentes options de résolution des trois algorithmes, comme le chemin à trouver.\\

Les fonctions d'importation et d'exportation des graphes sont également gérées par son intermédiaire, tout comme les tests, qui renvoient un fichier csv de résultats. Il est possible de choisir dans les tests l'algorithme à utiliser, ainsi que l'amplitude du test. \\

\end{document}